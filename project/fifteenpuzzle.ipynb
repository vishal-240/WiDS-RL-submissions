{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    num_cells = 16\n",
    "    size = 4\n",
    "\n",
    "    first_row_solved = None\n",
    "    second_row_solved = None\n",
    "    full_solved = None\n",
    "\n",
    "    def __init__(self,numbers):\n",
    "        self.numbers = np.array(numbers,dtype=int)\n",
    "        self.solved = self.count_solved_rows()\n",
    "        self.value = 0.0\n",
    "        self.policy = None\n",
    "        self.terminal = self.solved == 4\n",
    "        self.empty_index = np.where(self.numbers == 16)[0][0]\n",
    "\n",
    "    def count_solved_rows(self):\n",
    "        for i in range(16):\n",
    "            if self.numbers[i] != i+1:\n",
    "                if i<4:\n",
    "                    return 0\n",
    "                elif i<8:\n",
    "                    return 1\n",
    "                return 2\n",
    "        return 4\n",
    "    \n",
    "    def possible_actions(self):\n",
    "        actions = []\n",
    "        r = self.empty_index//4\n",
    "        c = self.empty_index%4\n",
    "        if r+1 < 4:\n",
    "            actions.append(self.empty_index+4)\n",
    "        if r-1 >= 0:\n",
    "            actions.append(self.empty_index-4)\n",
    "        if c+1 < 4:\n",
    "            actions.append(self.empty_index+1)\n",
    "        if c-1 >= 0:\n",
    "            actions.append(self.empty_index-1)\n",
    "        return actions\n",
    "    \n",
    "    def next_state(self,action):\n",
    "        new_numbers = self.numbers.copy()\n",
    "        new_numbers[self.empty_index] = new_numbers[action]\n",
    "        new_numbers[action] = 16\n",
    "        return State(new_numbers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "State.first_row_solved = State([1,2,3,4,16,0,0,0,0,0,0,0,0,0,0,0])\n",
    "State.second_row_solved = State([1,2,3,4,5,6,7,8,16,0,0,0,0,0,0,0])\n",
    "State.full_solved = State([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleSolver:\n",
    "    def __init__(self,γ = 0.9,theta = 0.1):\n",
    "        self.gamma = γ\n",
    "        self.theta = theta\n",
    "        self.states = {}\n",
    "        self.policy = {}\n",
    "    \n",
    "    def generate_states_from(self,state): #generating all the states from a given state\n",
    "        queue = deque([state])\n",
    "        while queue:\n",
    "            current = queue.popleft()\n",
    "            if tuple(current.numbers) in self.states:\n",
    "                continue\n",
    "            self.states[tuple(current.numbers)] = current\n",
    "            for a in current.possible_actions():\n",
    "                new_state = current.next_state(a)\n",
    "                queue.append(new_state)\n",
    "\n",
    "    def value_iteration(self):\n",
    "        while True:\n",
    "            δ = 0\n",
    "            for s in self.states.values():\n",
    "                if s.terminal:\n",
    "                    continue\n",
    "                v = s.value\n",
    "                action_values = [self.reward(s,s.next_state(a)) + self.gamma * self.states[tuple(s.next_state(a).numbers)].value for a in s.possible_actions()]\n",
    "                s.value = max(action_values)\n",
    "                best_action = s.possible_actions()[np.argmax(action_values)]\n",
    "                self.policy[tuple(s.numbers)] = best_action\n",
    "                δ = max(δ,abs(v-s.value))\n",
    "            if δ < self.theta:\n",
    "                break\n",
    "            \n",
    "    def reward(self, current, next):\n",
    "        if next.terminal:\n",
    "            return 100\n",
    "        return next.solved - current.solved\n",
    "    \n",
    "    def train(self): #training the agent for optimal actions\n",
    "        self.generate_states_from(State.first_row_solved)\n",
    "        self.generate_states_from(State.second_row_solved)\n",
    "        self.generate_states_from(State.full_solved)\n",
    "        self.value_iteration()\n",
    "\n",
    "    def random_state(self):\n",
    "        s = State.full_solved\n",
    "        for i in range(100):\n",
    "            s = s.next_state(random.random.choice(s.possible_actions()))\n",
    "        return s\n",
    "    \n",
    "    def start(self):\n",
    "        s = self.random_state()\n",
    "        T = 0\n",
    "        while not s.terminal:\n",
    "            print(s.numbers.reshape(4,4))\n",
    "            a = self.policy[tuple(s.numbers)]\n",
    "            s = s.next_state(a)\n",
    "            T += 1\n",
    "            print('-----------------')\n",
    "            print(f'T = {T}')\n",
    "        print(f'Done in {T} steps')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle = PuzzleSolver()\n",
    "puzzle.train()\n",
    "puzzle.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
